{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b26181",
   "metadata": {},
   "source": [
    "# Utilização do Modelo Word2Vec com GenSim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4202c8ac",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "Esta atividade envolve a pesquisa e utilização do modelo Word2Vec, utilizando a biblioteca GenSim do Python, para criar representações vetoriais de palavras a partir de um corpus escolhido. O objetivo é entender como os vetores de palavras podem capturar relações semânticas e contextuais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd8210",
   "metadata": {},
   "source": [
    "## Preparação dos Dados\n",
    "A preparação dos dados é um passo crucial antes de treinar o modelo Word2Vec. Este processo inclui:\n",
    "- **Remoção de Stopwords**: Eliminar palavras comuns que não contribuem significativamente para o sentido do texto.\n",
    "- **Lematização**: Reduzir as palavras às suas formas base, facilitando o agrupamento de variantes de uma mesma palavra.\n",
    "- **Tokenização**: Dividir o texto em palavras ou frases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a32a50",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo Word2Vec\n",
    "Com os dados preparados, o próximo passo é treinar o modelo Word2Vec. Utilizamos a biblioteca GenSim para este propósito, especificando parâmetros como o tamanho do vetor, a janela de contexto, e o número mínimo de ocorrências de palavras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b796bb4",
   "metadata": {},
   "source": [
    "## Exploração de Saídas do Word2Vec\n",
    "Após treinar o modelo, podemos explorar as saídas geradas. Isso inclui:\n",
    "- **Vetores de Palavras**: Cada palavra no corpus é representada por um vetor em um espaço dimensional.\n",
    "- **Similaridade entre Palavras**: Podemos calcular a similaridade entre vetores de palavras, o que nos dá uma medida de quão semanticamente relacionadas as palavras estão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438722f",
   "metadata": {},
   "source": [
    "## Exploração de Métodos da GenSim\n",
    "A biblioteca GenSim oferece vários métodos úteis para explorar e analisar o modelo Word2Vec treinado. Isso inclui encontrar palavras similares, calcular a similaridade entre pares de palavras, e muito mais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gustavohroos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gustavohroos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gustavohroos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gustavohroos/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('Lorde.tsv', sep='\\t')\n",
    "dados_limpos = dados.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Texto_Preparado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm a liability I'm a liability Much for me Yo...</td>\n",
       "      <td>[im, liability, im, liability, much, youre, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You asked if I was feeling it, I’m psycho high...</td>\n",
       "      <td>[ask, feel, im, psycho, high, know, wont, reme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Go back and tell it) Please could you be tend...</td>\n",
       "      <td>[go, back, tell, please, could, tender, sit, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Night, midnight, lose my mind Night, midnight,...</td>\n",
       "      <td>[night, midnight, lose, mind, night, midnight,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In my head, I play a supercut of us All the ma...</td>\n",
       "      <td>[head, play, supercut, u, magic, give, love, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Corpus  \\\n",
       "0  I'm a liability I'm a liability Much for me Yo...   \n",
       "1  You asked if I was feeling it, I’m psycho high...   \n",
       "2  (Go back and tell it) Please could you be tend...   \n",
       "3  Night, midnight, lose my mind Night, midnight,...   \n",
       "4  In my head, I play a supercut of us All the ma...   \n",
       "\n",
       "                                     Texto_Preparado  \n",
       "0  [im, liability, im, liability, much, youre, li...  \n",
       "1  [ask, feel, im, psycho, high, know, wont, reme...  \n",
       "2  [go, back, tell, please, could, tender, sit, c...  \n",
       "3  [night, midnight, lose, mind, night, midnight,...  \n",
       "4  [head, play, supercut, u, magic, give, love, l...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preparar_texto(texto):\n",
    "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto).lower()\n",
    "    \n",
    "    tokens = word_tokenize(texto)\n",
    "    \n",
    "    tokens_limpos = [palavra for palavra in tokens if palavra not in stopwords.words('english')]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def obter_pos_tag(word):\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "    \n",
    "    tokens_lematizados = [lemmatizer.lemmatize(w, obter_pos_tag(w)) for w in tokens_limpos]\n",
    "    \n",
    "    return tokens_lematizados\n",
    "\n",
    "dados_limpos['Texto_Preparado'] = dados_limpos['Corpus'].apply(preparar_texto)\n",
    "dados_limpos[['Corpus', 'Texto_Preparado']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('though', 0.3209531307220459),\n",
       " ('different', 0.30907854437828064),\n",
       " ('psycho', 0.2959253489971161),\n",
       " ('well', 0.29396384954452515),\n",
       " ('tie', 0.286493718624115),\n",
       " ('send', 0.2776780128479004),\n",
       " ('cadillacs', 0.27569177746772766),\n",
       " ('perfect', 0.26952219009399414),\n",
       " ('else', 0.26385262608528137),\n",
       " ('grocery', 0.2627700865268707)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencas = dados_limpos['Texto_Preparado'].tolist()\n",
    "\n",
    "modelo_word2vec = Word2Vec(sentences=sentencas, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "palavras_similares = modelo_word2vec.wv.most_similar('feeling', topn=10)\n",
    "\n",
    "palavras_similares"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
