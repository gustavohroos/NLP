{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tradução automática"
      ],
      "metadata": {
        "id": "ZJ42oUOgif_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Da biblioteca do Hugging Face, importamos \"mBART-50 many to many multilingual machine translation\" para carregar o modelo pré treinado e o seu tokenizador correspondente. Como o nome do modelo sugere, é possivel traduzir diretamente entre qualquer par de 50 idiomas."
      ],
      "metadata": {
        "id": "ZshOAdQbrlj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")"
      ],
      "metadata": {
        "id": "4nUKX8nrijIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui é inserido o texto que é desejada a tradução."
      ],
      "metadata": {
        "id": "DWrCXOq8tr_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The life is like a box of chocolates.\""
      ],
      "metadata": {
        "id": "W96uHetjl2La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobre o código a seguir, temos dois trechos semelhantes, um traduzindo para português e outro para espanhol.\n",
        "\n"
      ],
      "metadata": {
        "id": "svsk63mRtyB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As linhas quem contém \"tokenizer.src_lang = \" servem para informar a linguagem de origem do texto.\n",
        "\n",
        "Nas linhas com ``encoded_text = tokenizer(article_pt, return_tensors=\"pt\")``, estamos usando o tokenizador para converter o texto inserido para uma representação númerica em tensores PyTorch.\n",
        "\n",
        "Aqui ``generated_tokens = model.generate(**encoded_text, forced_bos_token_id=tokenizer.lang_code_to_id[\"pt_XX\"])``, estamos usando o modelo para gerar tokens. Estamos forçando o ID do token de início ``(\"forced_bos_token_id\")`` para inglês ``(\"pt_XX\")``. Isso significa que o modelo gerará a tradução começando com o token correspondente ao início de uma sequência em português.\n",
        "\n",
        "Finalmente, na hora de imprimir na tela, temos ``tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)`` significando que queremos pular a decodificação de tokens especiais durante o processo de reconversão dos tokens gerados de volta para texto legível."
      ],
      "metadata": {
        "id": "DMbgra7ius4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.src_lang = \"en_US\"\n",
        "\n",
        "encoded_text = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "generated_tokens = model.generate(\n",
        "    **encoded_text,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"pt_XX\"]\n",
        ")\n",
        "\n",
        "print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))\n",
        "\n",
        "generated_tokens = model.generate(\n",
        "    **encoded_text,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"es_XX\"]\n",
        ")\n",
        "\n",
        "print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3xz--WXlhSz",
        "outputId": "3a818e99-b474-45e1-e00b-fee92f31b4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A vida é como uma caixa de chocolates.']\n",
            "['La vida es como una caja de chocolates.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui carregamos um tokenizador e um modelo da biblioteca Hugging Face Transformers, específicos para tarefas de sequência para sequência (seq2seq)."
      ],
      "metadata": {
        "id": "QmzVaxxf7DVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
      ],
      "metadata": {
        "id": "Cy3QbLitvMm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.src_lang = \"pt_BR\"\n",
        "\n",
        "\n",
        "text_to_translate = \"A vida é como uma caixa de chocolates\"\n",
        "model_inputs = tokenizer(text_to_translate, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "gen_tokens = model.generate(**model_inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"])\n",
        "\n",
        "print(tokenizer.batch_decode(gen_tokens, skip_special_tokens=True))\n",
        "\n",
        "gen_tokens = model.generate(**model_inputs, forced_bos_token_id=tokenizer.lang_code_to_id['spa_Latn'])\n",
        "\n",
        "print(tokenizer.batch_decode(gen_tokens, skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I15_lYh-vnpg",
        "outputId": "a336b700-6332-4dfd-9e2a-41351b8352b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Life is like a box of chocolates.']\n",
            "['La vida es como una caja de chocolate.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yI2ea0oFF_WA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}